# -*- coding: utf-8 -*-
"""Analisis de Resultados NARMAX.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12EtsT7qLph1x6qevSqiCC7_4f7onVvwd

#Carga de datos y librerias
"""

#Pandas es utilizado para leer los set de datos
import pandas as pd
#Numpy es utilizado para generar las series de datos a graficar
import numpy as np
#Seaborn es utilizado para generar los gráficos
import seaborn as sns
import matplotlib.pyplot as plt
#Se importan modulos estadisticos para generar test de hipotesis, entre otros
from sklearn.preprocessing import StandardScaler,MinMaxScaler
#Módulos implementa funciones que evalúan el error de predicción para propósitos específicos
from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import mean_absolute_percentage_error as mape
from sklearn.metrics import mean_squared_error as mse

#Dividir arreglos o matrices en subconjuntos aleatorios de tren y prueba
from sklearn.model_selection import train_test_split

#Biblioteca de Redes Neuronales
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential,model_from_json
from keras.layers import Dropout, LSTM, Dense, Activation,Input
from tensorflow.keras.optimizers import SGD, Adam, RMSprop
from keras.callbacks import EarlyStopping, ModelCheckpoint

from hyperopt import Trials, STATUS_OK, tpe, hp, fmin, space_eval
from sklearn.model_selection import cross_val_score, KFold, cross_val_predict, TimeSeriesSplit
import time

pip install scikit-posthocs --quiet

# Para acceder a los archivos del gdrive
from google.colab import drive
drive.mount('/content/gdrive/')

cd /content/gdrive/MyDrive/Tesis/Datos

"""#Analsisis de Error de cada modelo"""

Narmax_result_mlp=pd.read_csv('Narmax_results_MLP_Wallmart.csv',index_col=0)
Narmax_result_gru=pd.read_csv('Narmax_results_GRU_Wallmart.csv',index_col=0)
Narmax_result_lstm=pd.read_csv('results_LSTM_Wallmart.csv',index_col=0)
Narmax_result_cnn=pd.read_csv('Narmax_results_CNN_Wallmart.csv',index_col=0)
Narmax_result_transformer=pd.read_csv('Narmax_results_Transformer_Wallmart.csv',index_col=0)
Narmax_result_svr=pd.read_csv('Narmax_results_SVR_Wallmart.csv',index_col=0)
Narmax_result_elm=pd.read_csv('Narmax_results_ELM_Wallmart.csv',index_col=0)

print(Narmax_result_mlp.shape)
print(Narmax_result_gru.shape)
print(Narmax_result_lstm.shape)
print(Narmax_result_cnn.shape)
print(Narmax_result_transformer.shape)
print(Narmax_result_svr.shape)
print(Narmax_result_elm.shape)

"""##ELM"""

Narmax_result_elm = Narmax_result_elm.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_elm.head(5)

print(Narmax_result_elm["time"].mean())
print(Narmax_result_elm["MSE"].mean())

"""##SVR"""

Narmax_result_svr = Narmax_result_svr.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_svr.head(5)

print(Narmax_result_svr["time"].mean())
print(Narmax_result_svr["MSE"].mean())

"""##MLP"""

Narmax_result_mlp = Narmax_result_mlp.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_mlp.head(5)

print(Narmax_result_mlp["time"].mean())
print(Narmax_result_mlp["MSE"].mean())

"""##GRU"""

Narmax_result_gru = Narmax_result_gru.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_gru.head(5)

print(Narmax_result_gru["time"].mean())
print(Narmax_result_gru["MSE"].mean())

"""##LSTM"""

Narmax_result_lstm = Narmax_result_lstm.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_lstm.head(5)

"""##CNN"""

Narmax_result_cnn= Narmax_result_cnn.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_cnn.head(5)

print(Narmax_result_cnn["time"].mean())
print(Narmax_result_cnn["MSE"].mean())

"""##Transformer"""

Narmax_result_transformer= Narmax_result_transformer.sort_values(by='MSE', ascending=True)
print("Top 5 mejores resultados")
Narmax_result_transformer.head(5)

print(Narmax_result_transformer["time"].mean())
print(Narmax_result_transformer["MSE"].mean())

"""#Se verifica normalidad de los errores de test"""

from scipy.stats import shapiro
import numpy as np
from scipy.stats import friedmanchisquare
from scikit_posthocs import posthoc_nemenyi
import scikit_posthocs as sp

def test_shapiro(data):
  stat, p = shapiro(data)
  print('stat=%.3f, p=%.5f' % (stat, p))
  if p > 0.05:
    print('Probably Gaussian')
    print("")
  else:
    print('Probably not Gaussian')
    print("")

print("Test de shapiro a Resutl MLP")
test_shapiro(Narmax_result_mlp["MSE"])

print("Test de shapiro a Resutl ELM")
test_shapiro(Narmax_result_elm["MSE"])

print("Test de shapiro a Resutl SVR")
test_shapiro(Narmax_result_svr["MSE"])

print("Test de shapiro a Resutl GRU")
test_shapiro(Narmax_result_gru["MSE"])

print("Test de shapiro a Resutl LSTM")
test_shapiro(Narmax_result_lstm["MSE"])

print("Test de shapiro a Resutl CNN")
test_shapiro(Narmax_result_cnn["MSE"])

print("Test de shapiro a Resutl transformer")
test_shapiro(Narmax_result_transformer["MSE"])



def grafico_distribucion(data):
  plt.subplots(figsize=(7,3))
  sns.histplot(x=data,kde=True,color="blue",bins=30)
  plt.tight_layout()
  plt.show()

grafico_distribucion(Narmax_result_mlp["MSE"])
grafico_distribucion(Narmax_result_cnn["MSE"])
grafico_distribucion(Narmax_result_lstm["MSE"])
grafico_distribucion(Narmax_result_transformer["MSE"])
grafico_distribucion(Narmax_result_gru["MSE"])
grafico_distribucion(Narmax_result_svr["MSE"])
grafico_distribucion(Narmax_result_elm["MSE"])

"""## Test de Friedman

"""

# Convertir los datos en un array 2D
data = np.array([Narmax_result_lstm["MSE"],Narmax_result_svr["MSE"],Narmax_result_elm["MSE"], Narmax_result_cnn["MSE"],Narmax_result_gru["MSE"],Narmax_result_mlp["MSE"],Narmax_result_transformer["MSE"]])
#data = np.array([result_lstm["MSE"], result_cnn["MSE"],result_gru["MSE"],result_mlp["MSE"],result_transformer["MSE"]])

# Realizar el test de Friedman
statistic, p_value = friedmanchisquare(*data)
print('stat=%.3f, p=%.3f' % (statistic, p_value))
nivel_significancia = 0.05
# Verificar si se rechaza o no la hipótesis nula
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""kruskal"""

from scipy.stats import kruskal
# Convertir los datos en un array 2D
data = np.array([Narmax_result_lstm["MSE"],Narmax_result_svr["MSE"],Narmax_result_elm["MSE"], Narmax_result_cnn["MSE"],Narmax_result_gru["MSE"],Narmax_result_mlp["MSE"],Narmax_result_transformer["MSE"]])

# Realizar el test de Friedman
statistic, p_value = kruskal(*data)
print('stat=%.3f, p=%.3f' % (statistic, p_value))
nivel_significancia = 0.05
# Verificar si se rechaza o no la hipótesis nula
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""## post-hoc 1"""

# Combinar los datos en un DataFrame
data_mse = pd.DataFrame({'LSTM':Narmax_result_lstm["MSE"],"SRV":Narmax_result_svr["MSE"], "ELM":Narmax_result_elm["MSE"], 'CNN':Narmax_result_cnn["MSE"], 'MLP': Narmax_result_mlp["MSE"],'GRU': Narmax_result_gru["MSE"],'Transformer':Narmax_result_transformer["MSE"]})
data_time = pd.DataFrame({'LSTM':Narmax_result_lstm["time"],"SRV":Narmax_result_svr["time"], "ELM":Narmax_result_elm["time"], 'CNN':Narmax_result_cnn["time"], 'MLP': Narmax_result_mlp["time"],'GRU': Narmax_result_gru["time"],'Transformer':Narmax_result_transformer["time"]})

"""kruskal"""

from scipy.stats import kruskal
# Convertir los datos en un array 2D
data = np.array([Narmax_result_lstm["MSE"],Narmax_result_svr["MSE"],Narmax_result_elm["MSE"], Narmax_result_cnn["MSE"],Narmax_result_gru["MSE"],Narmax_result_mlp["MSE"],Narmax_result_transformer["MSE"]])

# Realizar el test de Friedman
statistic, p_value = kruskal(*data)
print('stat=%.3f, p=%.3f' % (statistic, p_value))
nivel_significancia = 0.05
# Verificar si se rechaza o no la hipótesis nula
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

posthoc_df = sp.posthoc_mannwhitney([Narmax_result_lstm["MSE"],Narmax_result_svr["MSE"],Narmax_result_elm["MSE"],Narmax_result_cnn["MSE"],Narmax_result_mlp["MSE"],Narmax_result_gru["MSE"],Narmax_result_transformer["MSE"]], p_adjust = 'bonferroni')
group_names= ["LSTM", "SRV","ELM","CNN","MLP","GRU","Transformer"]
posthoc_df.columns= group_names
posthoc_df.index= group_names
posthoc_df.style.applymap(lambda x: "background-color:violet" if x<0.05 else "background-color: white")

data_mse.describe()

data_time.describe()

"""# Sección nueva"""

result_mlp=pd.read_csv('results_MLP_Wallmart.csv',index_col=0)
result_gru=pd.read_csv('results_GRU_Wallmart.csv',index_col=0)
result_lstm=pd.read_csv('results_LSTM_Wallmart.csv',index_col=0)
result_cnn=pd.read_csv('results_CNN_Wallmart.csv',index_col=0)
result_transformer=pd.read_csv('results_Transformer_Wallmart.csv',index_col=0)
result_svr=pd.read_csv('results_SVR_Wallmart.csv',index_col=0)
result_elm=pd.read_csv('results_ELM_Wallmart.csv',index_col=0)

pip install scipy --quiet

from scipy.stats import ranksums,mannwhitneyu

"""CNN"""

data_cnn_mse= np.array(result_cnn["MSE"])
data_cnn_mse_narmax= np.array(Narmax_result_cnn["MSE"])

statistic, p_value = mannwhitneyu(data_cnn_mse,data_cnn_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""GRU"""

data_gru_mse= np.array(result_gru["MSE"])
data_gru_mse_narmax= np.array(Narmax_result_gru["MSE"])

statistic, p_value = mannwhitneyu(data_gru_mse,data_gru_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""Transfomer"""

data_transformer_mse= np.array(result_transformer["MSE"])
data_transformer_mse_narmax= np.array(Narmax_result_transformer["MSE"])

statistic, p_value = mannwhitneyu(data_transformer_mse,data_transformer_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""MLP"""

data_mlp_mse= np.array(result_mlp["MSE"])
data_mlp_mse_narmax= np.array(Narmax_result_mlp["MSE"])

statistic, p_value = mannwhitneyu(data_mlp_mse,data_mlp_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""SVR"""

data_svr_mse= np.array(result_svr["MSE"])
data_svr_mse_narmax= np.array(Narmax_result_svr["MSE"])

statistic, p_value = mannwhitneyu(data_svr_mse,data_svr_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""LSTM"""

data_lstm_mse= np.array(result_lstm["MSE"])
data_lstm_mse_narmax= np.array(Narmax_result_lstm["MSE"])

statistic, p_value = mannwhitneyu(data_lstm_mse,data_lstm_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")

"""ELM"""

data_elm_mse= np.array(result_elm["MSE"])
data_elm_mse_narmax= np.array(Narmax_result_elm["MSE"])

statistic, p_value = mannwhitneyu(data_elm_mse,data_elm_mse_narmax)
# Verificar si se rechaza o no la hipótesis nula
nivel_significancia = 0.05
if p_value < nivel_significancia:
    print("Se rechaza la hipótesis nula. Hay diferencias significativas entre las medianas de los grupos.")
else:
    print("No se rechaza la hipótesis nula. No hay diferencias significativas entre las medianas de los grupos.")