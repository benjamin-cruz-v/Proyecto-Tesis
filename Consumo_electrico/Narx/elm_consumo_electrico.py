# -*- coding: utf-8 -*-
"""ELM_Consumo Electrico.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19ByOnSwqvDyxraDDYH6GfruCArg1dGqN

**Modelo de red neuronal ELM**

Este archivo consta de los codigos de:
* 1.Carga de librerias y datos
* 2.Proceso de entrenamiento
  * 2.1. Separacion de datos en train y test
  * 2.2 Modelo ELM
* 3.Evaluacion del modelo
* 4.Exportar resultados

#1.Carga de Librerias y Datos

*Se importan los módulos necesarios para trabajar*
"""

#Pandas es utilizado para leer los set de datos
import pandas as pd
#Numpy es utilizado para generar las series de datos a graficar
import numpy as np
#Seaborn es utilizado para generar los gráficos
import seaborn as sns
import matplotlib.pyplot as plt
#Se importan modulos estadisticos para generar test de hipotesis, entre otros
from sklearn.preprocessing import StandardScaler
#Módulos implementa funciones que evalúan el error de predicción para propósitos específicos
from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import mean_absolute_percentage_error as mape
from sklearn.metrics import mean_squared_error as mse
#Ignorar warnings
import warnings
warnings.filterwarnings("ignore")

#Dividir arreglos o matrices en subconjuntos aleatorios de tren y prueba
from sklearn.model_selection import train_test_split

from hyperopt import Trials, STATUS_OK, tpe, hp, fmin, space_eval
from sklearn.model_selection import cross_val_score, KFold, cross_val_predict, TimeSeriesSplit
import time

# Para acceder a los archivos del gdrive
from google.colab import drive
drive.mount('/content/gdrive/')

cd /content/gdrive/MyDrive/Tesis/Datos-ConsumoElectrico

"""##Se obtiene conjunto de datos"""

predictor_variables=pd.read_csv('predictor_variables.csv' ,index_col='dt')
target_variables=pd.read_csv('target_variables.csv' ,index_col='dt')

#Setear semilla
np.random.seed(42)

"""#2.Proceso de entrenamiento

**Se establece los parametros de:**
"""

#Se establece porcentaje de usado para test
PORCENTAJE_TEST=0.2

#Se define la cantidad de intentos de la optimizacion bayesiana
INTENTOS=100

"""##2.1. Separacion de data en train y test"""

#Se separa conjunto en entrenamiento y prueba; sin aleatoriedad
X_train, X_test, Y_train, Y_test = train_test_split(predictor_variables, target_variables, test_size=PORCENTAJE_TEST, shuffle=False)

shape_x_test=X_test.shape
shape_y_test=Y_test.shape

print("Separacion de datos terminada!")

"""##2.2 ELM"""

X_train_a=X_train.to_numpy()
Y_train_a=Y_train.to_numpy()
X_test_a=X_test.to_numpy()
Y_test_a=Y_test.to_numpy()

print(X_train_a.shape)
print(Y_train_a.shape)
print(X_test_a.shape)
print(Y_test_a.shape)

pip install hpelm --quiet

from hpelm import ELM
from sklearn.model_selection import cross_val_score, KFold
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials

# Definir la función objetivo
def objective(params):
    n_neurons = int(params['neurons'])
    activation = params['activation']



    #kf = KFold(n_splits=5)
    tscv = TimeSeriesSplit(n_splits=5)
    scores_mse = []
    scores_rmse = []
    scores_mae= []
    scores_mape= []
    times=[]
    models=[]
    aux=1000
    #Validacion cruzada
    for train_index, test_index in tscv.split(X_train_a):
      X_train_, X_test_ = X_train_a[train_index], X_train_a[test_index]
      y_train_, y_test_ = Y_train_a[train_index], Y_train_a[test_index]

      # Crear un objeto ELM
      model =ELM(X_train_a.shape[1], 1)

      # Añadir una capa oculta con los hiperparámetros
      model.add_neurons(n_neurons, activation)

      #Entrenamiento
      start = time.time()
      model.train(X_train_, y_train_)
      end = time.time()

      #Evaluacion del modelo
      y_pred = model.predict(X_test_a)
      score_mse = mse(Y_test_a, y_pred)
      rmse = np.sqrt(score_mse)  # Calcular el RMSE
      score_mae = mae(Y_test_a, y_pred)
      score_mape= mape(Y_test_a, y_pred)


      scores_mse.append(score_mse)
      scores_mae.append(score_mae)
      scores_mape.append(score_mape)
      scores_rmse.append(rmse)

      if(score_mse<aux):
        aux=score_mse
        best_model=model
        y_pred_=y_pred

      models.append(model)

      #Tiempo de la validadion cruzada
      time_val= end- start
      times.append(time_val)

    return {'loss': np.mean(score_mse),
            'status': STATUS_OK,
            'model': best_model,
            'params': params,
            'time':times,
            'predic':y_pred_,
            'scores_mse': scores_mse,
            'scores_mae': scores_mae,
            'scores_mape': scores_mape,
            'scores_rmse': scores_rmse,
            'models':models
            }

# Definir el espacio de búsqueda de hiperparámetros
space = {
    'neurons': hp.quniform('neurons', 100, 512, 2),
    'activation': hp.choice('activation', ['sigm', 'tanh']),
}

# Optimización bayesiana
trials = Trials()
best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)

print("Los mejores hiperparámetros son: ", best)

# Los resultados completos (incluyendo los scores de validación cruzada para cada evaluación) están en el objeto 'trials'

#Obtener el valor de la función objetivo del mejor ensayo
best_trial = trials.best_trial
predic = best_trial['result']['predic']

# Obtener una lista de los resultados de todas las evaluaciones
all_results = [trial['result'] for trial in trials]

#Grafico de prediccion con el valor real
tiempo=[x for x in range(predic.shape[0])]
plt.figure(figsize=(18,4))
plt.plot(tiempo,predic)
plt.ylabel('Global_active_power', size=15)
plt.plot(tiempo,Y_test)
plt.xlabel('Time step', size=15)
plt.legend(['Prediccion','Real'])
plt.show()

"""#Exportar resultados"""

#Del objeto all_results donde estan los resultados de cada trial de la optimizacion bayesiana se obtiene los parametros para exportalos a un csv
results=[]
trial=0 #Nº de intento de optimizacion bayesiana

for result in all_results:
  k=0 #validacion cruzada
  trial+=1
  for time,score_mse,score_mae,score_mape,score_rmse in zip(result['time'],result['scores_mse'],result['scores_rmse'],result['scores_mae'],result['scores_mape']):
    k+=1
    nameModel = "ELM" + "_"+str(result['params']['activation'])+"_"+str(result['params']['neurons'])
    results.append([nameModel,trial,k,time,score_mse,score_rmse,score_mae,score_mape])

#Se crea dataframe
results_csv=pd.DataFrame(results,columns=['nameModel','trial_optimizacion_bayesiana','Step_validacion','time','MSE','RMSE','MAE','MAPE'])

results_o = results_csv.sort_values(by='MSE', ascending=True)
results_o.head(5)

# Exportar el DataFrame como CSV
results_csv.to_csv('results_ELM_CE.csv')

"""#Narmax"""

best_model=all_results[85]["models"][4]

predictor_variables=pd.read_csv('predictor_variables.csv', index_col='dt')
target_variables=pd.read_csv('target_variables.csv', index_col='dt')
df=pd.read_csv('df_modelo.csv', index_col='dt')

predictor_variables=predictor_variables.to_numpy()
target_variables=target_variables.to_numpy()

"""## Generar Narmax data

"""

def narmax_data(data,modelo,predictor,retrasos):
  #Se realiza prediccion
  results = modelo.predict(predictor)
  target = np.array(target_variables)
  error=[]
  aux=0
  for prediccion, real in zip(results,target):
    aux=real-prediccion
    error.append(aux[0])

  df_narmax = data.iloc[retrasos:]
  # Agregamos el arreglo como nueva columna en el DataFrame
  df_narmax['error'] = error

  return df_narmax

df=narmax_data(df,best_model,predictor_variables,3)
df

"""##2.Normalizar base de datos

El **método de puntuación z** (a menudo llamado estandarización ) transforma los datos en una distribución con una media de 0 y una desviación estándar de 1 . Cada valor estandarizado se calcula restando la media de la característica correspondiente y luego dividiendo por la desviación estándar.
"""

#Seleccion de caracteristicas
features =df.columns

#Se define escalado
std_scaler = StandardScaler()

#Transformacion

for i in features:
  df[i] = std_scaler.fit_transform(df[i].values.reshape(-1,1))

df.head()

"""##3.Preparar datos para realizar aprendizaje supervizado.

La idea es modelar cada valor en función de los valores recientes anteriores, dado un retardo de tiempo dado. **Los valores futuros de una variable en una serie de tiempo dependen de sus propios rezagos y de los rezagos de otras variables.**
"""

def time_delay_embedding(series: pd.Series, n_lags: int, horizon: int):
    """
    Incrustación de retardo de tiempo
    :param series: serie de tiempo como objeto de pandas
    :param n_lags: número de valores pasados para usar como variables explicativas
    :param horizon: horizonte de pronostico
    :return:pd.DataFrame con series temporales reconstruidas
    """
    assert isinstance(series, pd.Series)

    if series.name is None:
        name = 'Series'
    else:
        name = series.name

    n_lags_iter = list(range(n_lags, -horizon, -1))

    serie_time_delay = [series.shift(i) for i in n_lags_iter]
    serie_time_delay = pd.concat(serie_time_delay, axis=1).dropna()
    serie_time_delay.columns = [f'{name}(t-{j - 1})'
                 if j > 0 else f'{name}(t+{np.abs(j) + 1})'
                 for j in n_lags_iter]

    return serie_time_delay

serie_split = []
for columna in df:
  col_df = time_delay_embedding(
      df[columna], #Serie de tiempo
      n_lags=3, #Numero de retrasos
      horizon=1 # Horizonte de prediccion
      )
  serie_split.append(col_df)

serie_df = pd.concat(serie_split, axis=1).dropna()
serie_df.head()

predictor_variables = serie_df.columns.str.contains('\(t\-')
target_variables = serie_df.columns.str.contains('Global_active_power\(t\+')

predictor_variables = serie_df.iloc[:, predictor_variables]
target_variables = serie_df.iloc[:, target_variables]

#Se separa conjunto en entrenamiento y prueba; sin aleatoriedad
#Dejando un %30 de la data para test
X_train, X_test, Y_train, Y_test = train_test_split(predictor_variables, target_variables, test_size=0.2, shuffle=False)

shape=len(X_train.columns)

print("Separacion de datos terminada!")

X_train.shape

"""##ELM"""

X_train_a=X_train.to_numpy()
Y_train_a=Y_train.to_numpy()
X_test_a=X_test.to_numpy()
Y_test_a=Y_test.to_numpy()

print(X_train_a.shape)
print(Y_train_a.shape)
print(X_test_a.shape)
print(Y_test_a.shape)

from hpelm import ELM
from sklearn.model_selection import cross_val_score, KFold
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials

# Definir la función objetivo
def objective(params):
    n_neurons = int(params['neurons'])
    activation = params['activation']



    #kf = KFold(n_splits=5)
    tscv = TimeSeriesSplit(n_splits=5)
    scores_mse = []
    scores_rmse = []
    scores_mae= []
    scores_mape= []
    times=[]
    models=[]
    #Validacion cruzada
    for train_index, test_index in tscv.split(X_train_a):
      X_train_, X_test_ = X_train_a[train_index], X_train_a[test_index]
      y_train_, y_test_ = Y_train_a[train_index], Y_train_a[test_index]

      # Crear un objeto ELM
      model =ELM(X_train_a.shape[1], 1)

      # Añadir una capa oculta con los hiperparámetros
      model.add_neurons(n_neurons, activation)

      #Entrenamiento
      start = time.time()
      model.train(X_train_, y_train_)
      end = time.time()

      #Evaluacion del modelo
      y_pred = model.predict(X_test_a)
      score_mse = mse(Y_test_a, y_pred)
      rmse = np.sqrt(score_mse)  # Calcular el RMSE
      score_mae = mae(Y_test_a, y_pred)
      score_mape= mape(Y_test_a, y_pred)


      scores_mse.append(score_mse)
      scores_mae.append(score_mae)
      scores_mape.append(score_mape)
      scores_rmse.append(rmse)

      models.append(model)

      #Tiempo de la validadion cruzada
      time_val= end- start
      times.append(time_val)

    return {'loss': np.mean(score_mse),
            'status': STATUS_OK,
            'model': model,
            'params': params,
            'time':times,
            'predic':y_pred,
            'scores_mse': scores_mse,
            'scores_mae': scores_mae,
            'scores_mape': scores_mape,
            'scores_rmse': scores_rmse,
            'models':models
            }

# Definir el espacio de búsqueda de hiperparámetros
space = {
    'neurons': hp.quniform('neurons', 100, 512, 2),
    'activation': hp.choice('activation', ['sigm', 'tanh']),
}

# Optimización bayesiana
trials = Trials()
best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=100, trials=trials)

print("Los mejores hiperparámetros son: ", best)

# Los resultados completos (incluyendo los scores de validación cruzada para cada evaluación) están en el objeto 'trials'

#Obtener el valor de la función objetivo del mejor ensayo
best_trial = trials.best_trial
predic = best_trial['result']['predic']

# Obtener una lista de los resultados de todas las evaluaciones
all_results = [trial['result'] for trial in trials]

#Grafico de prediccion con el valor real
tiempo=[x for x in range(predic.shape[0])]
plt.figure(figsize=(18,4))
plt.plot(tiempo,predic)
plt.ylabel('Global_active_power', size=15)
plt.plot(tiempo,Y_test)
plt.xlabel('Time step', size=15)
plt.legend(['Prediccion','Real'])
plt.show()

"""##Exportar resultados"""

#Del objeto all_results donde estan los resultados de cada trial de la optimizacion bayesiana se obtiene los parametros para exportalos a un csv
results=[]
trial=0 #Nº de intento de optimizacion bayesiana

for result in all_results:
  k=0 #validacion cruzada
  trial+=1
  for time,score_mse,score_mae,score_mape,score_rmse in zip(result['time'],result['scores_mse'],result['scores_rmse'],result['scores_mae'],result['scores_mape']):
    k+=1
    nameModel = "Narmax_ELM" + "_"+str(result['params']['activation'])+"_"+str(result['params']['neurons'])
    results.append([nameModel,trial,k,time,score_mse,score_rmse,score_mae,score_mape])

#Se crea dataframe
results_csv=pd.DataFrame(results,columns=['nameModel','trial_optimizacion_bayesiana','Step_validacion','time','MSE','RMSE','MAE','MAPE'])

results_o = results_csv.sort_values(by='MSE', ascending=True)
results_o.head(5)

# Exportar el DataFrame como CSV
results_csv.to_csv('Narmax_results_ELM_CE.csv')